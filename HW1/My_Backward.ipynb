{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5])\n",
      "torch.Size([10])\n",
      "torch.Size([7, 10])\n",
      "torch.Size([7])\n",
      "torch.Size([3, 7])\n",
      "torch.Size([3])\n",
      "Comparison of gradients for layer 0 parameters:\n",
      "Manual Calculation:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 4.4902e-03, -4.2915e-03,  1.8676e-03, -1.3113e-03, -1.7484e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.0697e-01,  1.0109e-01, -4.3909e-02,  3.1749e-02,  4.1286e-02],\n",
      "        [ 5.4955e-02, -5.1975e-02,  2.2531e-02, -1.6371e-02, -2.1259e-02],\n",
      "        [-2.7816e-04,  2.7816e-04, -7.9473e-05,  3.9736e-05,  7.9473e-05],\n",
      "        [-2.3564e-02,  2.2292e-02, -9.6957e-03,  6.9936e-03,  9.0599e-03],\n",
      "        [-2.7061e-02,  2.5590e-02, -1.1086e-02,  8.0665e-03,  1.0451e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-9.5367e-03,  9.0599e-03, -3.8942e-03,  2.8213e-03,  3.6558e-03]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "Automatic Differentiation:\n",
      " tensor([[ 0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 4.5020e-03, -4.2569e-03,  1.8475e-03, -1.3371e-03, -1.7357e-03],\n",
      "        [ 0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [-1.0698e-01,  1.0115e-01, -4.3901e-02,  3.1774e-02,  4.1245e-02],\n",
      "        [ 5.4968e-02, -5.1976e-02,  2.2558e-02, -1.6326e-02, -2.1193e-02],\n",
      "        [-2.9976e-04,  2.8344e-04, -1.2302e-04,  8.9033e-05,  1.1557e-04],\n",
      "        [-2.3566e-02,  2.2283e-02, -9.6708e-03,  6.9993e-03,  9.0856e-03],\n",
      "        [-2.7048e-02,  2.5575e-02, -1.1100e-02,  8.0335e-03,  1.0428e-02],\n",
      "        [ 0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [-9.5563e-03,  9.0361e-03, -3.9217e-03,  2.8383e-03,  3.6844e-03]],\n",
      "       device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Comparison of gradients for layer 1 parameters:\n",
      "Manual Calculation:\n",
      " tensor([ 0.0000,  0.0028,  0.0000, -0.0665,  0.0342, -0.0002, -0.0146, -0.0168,\n",
      "         0.0000, -0.0059], device='cuda:0', grad_fn=<CopySlices>)\n",
      "Automatic Differentiation:\n",
      " tensor([ 0.0000,  0.0028,  0.0000, -0.0665,  0.0342, -0.0002, -0.0146, -0.0168,\n",
      "         0.0000, -0.0059], device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Comparison of gradients for layer 2 parameters:\n",
      "Manual Calculation:\n",
      " tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000, -0.0171,  0.0000, -0.0183, -0.0567, -0.0216, -0.0131, -0.0995,\n",
      "          0.0000, -0.0333],\n",
      "        [ 0.0000,  0.0155,  0.0000,  0.0167,  0.0518,  0.0197,  0.0119,  0.0910,\n",
      "          0.0000,  0.0306],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000, -0.0283,  0.0000, -0.0305, -0.0945, -0.0361, -0.0218, -0.1660,\n",
      "          0.0000, -0.0557]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "Automatic Differentiation:\n",
      " tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [-0.0000, -0.0170, -0.0000, -0.0183, -0.0567, -0.0216, -0.0131, -0.0996,\n",
      "         -0.0000, -0.0334],\n",
      "        [ 0.0000,  0.0156,  0.0000,  0.0167,  0.0518,  0.0198,  0.0119,  0.0910,\n",
      "          0.0000,  0.0305],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [-0.0000, -0.0284, -0.0000, -0.0305, -0.0945, -0.0361, -0.0218, -0.1660,\n",
      "         -0.0000, -0.0556]], device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Comparison of gradients for layer 3 parameters:\n",
      "Manual Calculation:\n",
      " tensor([ 0.0000,  0.0000, -0.0632,  0.0577,  0.0000,  0.0000, -0.1054],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "Automatic Differentiation:\n",
      " tensor([ 0.0000,  0.0000, -0.0632,  0.0578,  0.0000,  0.0000, -0.1054],\n",
      "       device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Comparison of gradients for layer 4 parameters:\n",
      "Manual Calculation:\n",
      " tensor([[ 0.0000,  0.0000, -0.0233, -0.0653,  0.0000,  0.0000, -0.0283],\n",
      "        [ 0.0000,  0.0000, -0.0232, -0.0650,  0.0000,  0.0000, -0.0281],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "Automatic Differentiation:\n",
      " tensor([[-0.0000, -0.0000, -0.0233, -0.0653, -0.0000, -0.0000, -0.0283],\n",
      "        [-0.0000, -0.0000, -0.0232, -0.0650, -0.0000, -0.0000, -0.0281],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Comparison of gradients for layer 5 parameters:\n",
      "Manual Calculation:\n",
      " tensor([-0.1604, -0.1597,  0.0000], device='cuda:0', grad_fn=<CopySlices>)\n",
      "Automatic Differentiation:\n",
      " tensor([-0.1604, -0.1597,  0.0000], device='cuda:0')\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPS = 1e-3*0.75\n",
    "\n",
    "\n",
    "# Define a multi-layer neural network with variable number of layers\n",
    "class MultiLayerNet(nn.Module):\n",
    "    def __init__(self, layer_sizes):\n",
    "        super(MultiLayerNet, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            layers.append(nn.Linear(layer_sizes[i], layer_sizes[i+1]))\n",
    "            layers.append(nn.ReLU())  # Adding ReLU activation between layers\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "def compute_gradients_central_difference(model, x, y):\n",
    "    # Initialize gradients for manual computation\n",
    "    layer_gradients_manual = [torch.zeros_like(param) for param in model.parameters()]\n",
    "\n",
    "    # Perform central difference method for gradient approximation\n",
    "    for layer_idx, layer in enumerate(model.layers):\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            for i in range(layer.weight.shape[0]):\n",
    "                for j in range(layer.weight.shape[1]):\n",
    "                    # Perturb weights\n",
    "                    layer.weight.data[i, j] += EPS\n",
    "                    # Forward pass with positive perturbation\n",
    "                    z_pos = model(x)\n",
    "                    loss_pos = nn.functional.binary_cross_entropy_with_logits(z_pos, y)\n",
    "                    \n",
    "                    # Perturb weights back\n",
    "                    layer.weight.data[i, j] -= 2 * EPS\n",
    "                    # Forward pass with negative perturbation\n",
    "                    z_neg = model(x)\n",
    "                    loss_neg = nn.functional.binary_cross_entropy_with_logits(z_neg, y)\n",
    "                    \n",
    "                    # Central difference gradient approximation\n",
    "                    layer_gradients_manual[layer_idx][i, j] = (loss_pos - loss_neg) / (2 * EPS)\n",
    "                    \n",
    "                    # Restore weights\n",
    "                    layer.weight.data[i, j] += EPS\n",
    "\n",
    "            # Compute gradients for bias\n",
    "            for i in range(layer.bias.shape[0]):\n",
    "                # Perturb bias\n",
    "                layer.bias.data[i] += EPS\n",
    "                # Forward pass with positive perturbation\n",
    "                z_pos = model(x)\n",
    "                loss_pos = nn.functional.binary_cross_entropy_with_logits(z_pos, y)\n",
    "                \n",
    "                # Perturb bias back\n",
    "                layer.bias.data[i] -= 2 * EPS\n",
    "                # Forward pass with negative perturbation\n",
    "                z_neg = model(x)\n",
    "                loss_neg = nn.functional.binary_cross_entropy_with_logits(z_neg, y)\n",
    "                \n",
    "                # Central difference gradient approximation for bias\n",
    "                layer_gradients_manual[layer_idx+1][i] = (loss_pos - loss_neg) / (2 * EPS)\n",
    "                \n",
    "                # Restore bias\n",
    "                layer.bias.data[i] += EPS\n",
    "\n",
    "    return layer_gradients_manual\n",
    "\n",
    "# Create an instance of the network with n layers\n",
    "layer_sizes = [5, 10, 7, 3]  # Example: 4 layers (input size, hidden sizes, output size)\n",
    "model = MultiLayerNet(layer_sizes).to(device)\n",
    "\n",
    "# Input tensor (batch size 1, input size 5)\n",
    "x = torch.randn(5, requires_grad=True, device=device)\n",
    "\n",
    "# Expected output tensor (batch size 1, output size 3)\n",
    "y = torch.randint(0, 2, (3,), device=device).float()\n",
    "\n",
    "# Compute gradients using central difference (manual computation)\n",
    "layer_gradients_manual = compute_gradients_central_difference(model, x, y)\n",
    "\n",
    "# Compute gradients using backward method (automatic differentiation)\n",
    "model.zero_grad()\n",
    "z = model(x)\n",
    "loss = nn.functional.binary_cross_entropy_with_logits(z, y)\n",
    "loss.backward()\n",
    "\n",
    "# Initialize gradients for automatic differentiation\n",
    "layer_gradients_automatic = [param.grad.clone() for param in model.parameters()]\n",
    "for l in layer_gradients_manual:\n",
    "    print(l.shape)\n",
    "# Compare gradients\n",
    "for idx, (grad_manual, grad_automatic) in enumerate(zip(layer_gradients_manual, layer_gradients_automatic)):\n",
    "    print(f\"Comparison of gradients for layer {idx} parameters:\")\n",
    "    print(\"Manual Calculation:\\n\", grad_manual)\n",
    "    print(\"Automatic Differentiation:\\n\", grad_automatic)\n",
    "    print(\"--------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
